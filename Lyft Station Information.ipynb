{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googlemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "#open up a firefox broswer and navigate to the webpage.\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "#send the browser to the jsin location\n",
    "# this veribile has to be set to page_source\n",
    "page_source = driver.get('https://gbfs.baywheels.com/gbfs/en/station_information.json')\n",
    "\n",
    "#create a BeautifulSoup object from source json\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "#grabs body from json\n",
    "stations = json.loads(soup.find(\"body\").text)\n",
    "\n",
    "#further refines the output, eliminates meta data. outputs a dict:\n",
    "print(stations['ttl'])\n",
    "stations = stations['data']['stations']\n",
    "\n",
    "#closes webdrive\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put into pandas dataframe\n",
    "df = pd.DataFrame(stations)\n",
    "\n",
    "#get rid of columns that are not of interest to the project\n",
    "df = df.drop(axis=1, labels = ['rental_methods', 'external_id', 'has_kiosk','eightd_has_key_dispenser', 'electric_bike_surcharge_waiver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unused stations (unused defined as stations with 0 capcaity)\n",
    "df = df.loc[df['capacity'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = []\n",
    "\n",
    "for i in google_results:\n",
    "    zips.append(i[0][0].split(',')[2][-5:])\n",
    "    \n",
    "cities = []\n",
    "\n",
    "for i in google_results:\n",
    "    cities.append(i[0][0].split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe of SF stations only\n",
    "sf = df[df[\"city\"] == \" San Francisco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use google geoliocate API to convert lat/long of stations to addresss with zip code\n",
    "\n",
    "# from geopy.geocoders import GoogleV3\n",
    "\n",
    "# geolocator = GoogleV3(api_key='userkey') #creates geolocator object\n",
    "# test_station = geolocator.reverse(\"37.78637526861584, -122.40490436553954\") #station id 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the results of the google quarry above and saves to pd.dataframe\n",
    "#google_results_df = pd.DataFrame(google_results)\n",
    "\n",
    "#saves the pd.dataframe as .csv\n",
    "#df.to_csv('data/lyft/stations_google_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trips = pd.read_csv('data/lyft/unique_trips')\n",
    "unique_trips = unique_trips[['station1','station2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = []\n",
    "\n",
    "for i in google_results:\n",
    "    zips.append(i[0][0].split(',')[2][-5:])\n",
    "    \n",
    "cities = []\n",
    "\n",
    "for i in google_results:\n",
    "    cities.append(i[0][0].split(',')[1])\n",
    "\n",
    "#adds zip codes from google reverse geocoding as column\n",
    "df['zip'] = zips\n",
    "\n",
    "#adds city from google reverse geocoding as column\n",
    "df['city'] = cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#routes is a set of all possilbe paths between two stations within the SF stations dataframe\n",
    "routes = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds unique trips to routes. unique is defined as \n",
    "for i in sf_stations.station_id:\n",
    "    for j in sf_stations.station_id:\n",
    "        if (int(j),int(i)) not in routes:\n",
    "            routes.add((int(i),int(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = 'userkey'#enter Google Maps API key\n",
    "gmaps = googlemaps.Client(key=API_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trips = pd.DataFrame(routes, columns=['station1', 'station2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76    37.771058\n",
       "Name: lat, dtype: float64"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lat_lon(station_id):\n",
    "    station_id = str(station_id)\n",
    "    return (df.loc[df['station_id'] == station_id]['lat'], df.loc[df['station_id'] == station_id]['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9    37.796389\n",
      "Name: lat, dtype: float64, 9   -122.394586\n",
      "Name: lon, dtype: float64)\n",
      "(76    37.771058\n",
      "Name: lat, dtype: float64, 76   -122.402717\n",
      "Name: lon, dtype: float64)\n",
      "----\n",
      "Start station: 12, end station 90)\n",
      "3608\n",
      "801\n",
      "(33    37.785377\n",
      "Name: lat, dtype: float64, 33   -122.396906\n",
      "Name: lon, dtype: float64)\n",
      "(Series([], Name: lat, dtype: float64), Series([], Name: lon, dtype: float64))\n",
      "----\n",
      "Start station: 37, end station 505)\n",
      "3608\n",
      "801\n"
     ]
    }
   ],
   "source": [
    "#google_trip_results = []\n",
    "for i in unique_trips[36:38].iterrows():\n",
    "    \n",
    "    origin = get_lat_lon(i[0][0])\n",
    "    destination = get_lat_lon(i[1][1])\n",
    "    print(origin)\n",
    "    print(destination)\n",
    "    print(\"----\")\n",
    "    \n",
    "    #result = (gmaps.distance_matrix(origin, destination, mode = 'bicycling', units = 'imperial'))\n",
    "    #google_trip_results.append({'distance':result['rows'][0]['elements'][0][\"distance\"][\"value\"],'duration':result['rows'][0]['elements'][0][\"duration\"][\"value\"]})\n",
    "    print(f'Start station: {i[1][0]}, end station {i[1][1]})')\n",
    "    print(result['rows'][0]['elements'][0][\"distance\"][\"value\"]) #distance\n",
    "    print(result['rows'][0]['elements'][0][\"duration\"][\"value\"]) #duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trips.to_csv('data/lyft/unique_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/lyft/stations.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
